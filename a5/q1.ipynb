{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "from keras.models import model_from_json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_facenet():\n",
    "    \"\"\"\n",
    "    loads a saved pretrained model from a json file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # load json and create model\n",
    "    json_file = open('a5/FRmodel.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    FRmodel = model_from_json(loaded_model_json)\n",
    "\n",
    "    # load weights into new model\n",
    "    FRmodel.load_weights(\"a5/FRmodel.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    return FRmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def img_to_encoding(img1, model):\n",
    "    \"\"\"\n",
    "    returns 128-dimensional face embedding for input image\n",
    "    :param img1:\n",
    "    :param model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\n",
    "    if not os.path.exists('a5/saved_faces/'):\n",
    "        os.makedirs('a/5saved_faces')\n",
    "\n",
    "    a = np.load('a5/faces.npy')\n",
    "\n",
    "    for i in range(a.shape[0]):\n",
    "\n",
    "        img = a[i][..., ::-1]\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        cv2.imwrite(\"a5/saved_faces/face_image_\"+str(i)+\".jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Kmeans(X):\n",
    "    kmeans = KMeans(n_clusters=6).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    result = {}\n",
    "    result[-1] = \"no matching\"\n",
    "    result[0] = []\n",
    "    result[1] = []\n",
    "    result[2] = []\n",
    "    result[3] = []\n",
    "    result[4] = []\n",
    "    result[5] = []\n",
    "    for i in range(len(labels)):\n",
    "        result[labels[i]].append(i)\n",
    "    print(result)\n",
    "    visual_word = kmeans.cluster_centers_\n",
    "    print(visual_word)\n",
    "    return result,visual_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(img,model,visual_word):\n",
    "    ref_embedding = img_to_encoding(img,model)\n",
    "    max_sim = 0\n",
    "    max_idx = 0\n",
    "    for i in range(len(visual_word)):\n",
    "        sim = np.dot(visual_word[i],ref_embedding.T)/np.linalg.norm(ref_embedding)*np.linalg.norm(visual_word[i])\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            max_idx = i\n",
    "    if max_sim < 0.8:\n",
    "        return -1\n",
    "    return max_idx\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "(200, 128)\n",
      "{-1: 'no matching', 0: [8, 17, 18, 20, 27, 28, 37, 40, 44, 55, 60, 67, 74, 76, 82, 86, 90, 92, 93, 99, 110, 118, 121, 126, 127, 128, 129, 134, 137, 141, 147, 151, 153, 155, 159, 163, 167, 173, 181, 185, 196], 1: [0, 1, 2, 5, 7, 11, 14, 16, 23, 31, 36, 48, 52, 56, 61, 66, 70, 79, 81, 83, 88, 101, 112, 116, 148, 149, 154, 156, 162, 172, 177, 184, 190, 198, 199], 2: [32, 33, 45, 54, 57, 62, 77, 80, 84, 89, 98, 100, 105, 106, 108, 117, 119, 122, 135, 140, 145, 157, 161, 165, 180, 186, 187, 189, 192, 194, 197], 3: [9, 10, 12, 13, 26, 34, 39, 42, 43, 53, 59, 63, 64, 65, 68, 72, 73, 75, 85, 91, 94, 97, 102, 103, 107, 111, 113, 132, 136, 142, 170, 178, 183, 191], 4: [3, 21, 24, 25, 29, 30, 35, 41, 46, 49, 51, 71, 78, 104, 114, 115, 120, 123, 124, 125, 139, 146, 150, 152, 164, 166, 168, 169, 171, 174, 176, 182, 193, 195], 5: [4, 6, 15, 19, 22, 38, 47, 50, 58, 69, 87, 95, 96, 109, 130, 131, 133, 138, 143, 144, 158, 160, 175, 179, 188]}\n",
      "[[ 0.06931463  0.03432185 -0.06917591 -0.07583334  0.13540635  0.16368388\n",
      "   0.097882    0.013669   -0.06960553 -0.03115064  0.04599892  0.07520832\n",
      "   0.13154794  0.01752999  0.00799919 -0.0603486  -0.00904257 -0.05368889\n",
      "  -0.09795243  0.19513862  0.07403279 -0.0212435   0.02065409  0.05225572\n",
      "  -0.08643704 -0.01707137 -0.11796424 -0.08502355  0.10906782  0.04737639\n",
      "  -0.0159447   0.02259639 -0.06692238  0.04961461 -0.02707319  0.08268165\n",
      "  -0.00521704  0.15644975 -0.04679772 -0.01406511  0.07073731  0.03286445\n",
      "  -0.10190445 -0.03555372 -0.16911395  0.01971027  0.07453065  0.05495858\n",
      "  -0.10061258  0.02091208 -0.14090999 -0.00799305 -0.06987556  0.03435576\n",
      "   0.08302827  0.00940888 -0.10297229  0.19472655 -0.15542164 -0.02389035\n",
      "  -0.12317853  0.06068775  0.23531245 -0.1803371   0.09144516  0.04085671\n",
      "   0.04978104  0.08346613 -0.0981711  -0.04146063  0.07921152  0.0866842\n",
      "  -0.00893411  0.05837122  0.06159045  0.08076557 -0.00356835  0.00439833\n",
      "   0.08700132 -0.0177684  -0.04506085  0.03338959 -0.02028969 -0.01057285\n",
      "  -0.02487915  0.01353847  0.08434874  0.08577358  0.03930427  0.03781235\n",
      "   0.15940948 -0.15694798  0.01078128  0.08094948 -0.02164518 -0.16267015\n",
      "   0.01438439 -0.01583002  0.01329485  0.01169436  0.00863458 -0.00349545\n",
      "  -0.08640948  0.04699678 -0.18439382  0.18651136 -0.0403627   0.03029652\n",
      "   0.02399407 -0.0312331   0.05446126  0.0996148  -0.05650687  0.06414798\n",
      "   0.03188091  0.06430222 -0.13953468 -0.03453121 -0.0396775   0.11743242\n",
      "  -0.06055165 -0.04891702  0.00273278  0.09833733 -0.05384495  0.13626113\n",
      "  -0.06856077 -0.07435613]\n",
      " [ 0.09746906  0.0316144  -0.00311371 -0.06606888  0.14284899  0.16388881\n",
      "   0.09182285 -0.01311551 -0.03981445 -0.05907701  0.01571643  0.07332104\n",
      "   0.1170156   0.06699239  0.05741927 -0.07429951  0.02273437 -0.04777757\n",
      "  -0.1064278   0.16808539  0.05742164  0.07473428 -0.02714208  0.09020083\n",
      "  -0.09383627 -0.07126616 -0.13702315 -0.02513306  0.05454415  0.09626118\n",
      "  -0.04451956  0.03217577 -0.05314504  0.07560972  0.01411706  0.10963179\n",
      "   0.05442458  0.0732766  -0.05112877 -0.02399694  0.0570497   0.04273582\n",
      "  -0.04842828 -0.11703613 -0.11059987  0.07850864  0.0457765   0.06916119\n",
      "  -0.08296703  0.05534469 -0.09853324 -0.01347862 -0.02096908  0.05438209\n",
      "   0.11935534  0.02117838 -0.11851721  0.14629567 -0.15844026  0.00628027\n",
      "  -0.08571536  0.11514531  0.13976954 -0.19211527  0.04356024  0.04503441\n",
      "   0.05598476  0.09439996 -0.13396712 -0.04086653  0.10100936  0.04283237\n",
      "  -0.02209185  0.00039471  0.05046203  0.14436548  0.02621883 -0.02936631\n",
      "   0.11194551 -0.02355875  0.03186202  0.07087019 -0.02547271  0.0048127\n",
      "   0.01424591  0.01733046  0.04805891  0.0488809  -0.01007463  0.14813211\n",
      "   0.15926909 -0.16427263  0.03230869  0.14387338 -0.08762824 -0.0946692\n",
      "  -0.00851018 -0.06377893  0.04197923  0.0129038   0.07742496  0.0270348\n",
      "  -0.10554585  0.01162005 -0.19321546  0.16684127 -0.07084759 -0.04391031\n",
      "  -0.04912272  0.02259006  0.08228877  0.04634713 -0.04308032  0.04127561\n",
      "  -0.01147182  0.07517793 -0.1352379  -0.00719559 -0.1130784   0.11010585\n",
      "  -0.02452119 -0.04558721  0.02114115  0.08519544 -0.02794401  0.15360265\n",
      "  -0.02714115 -0.12463824]\n",
      " [ 0.10999983 -0.01640587 -0.01993587 -0.0595941   0.1328556   0.17424193\n",
      "   0.11861283  0.02389661 -0.04659316 -0.09134914 -0.00561757  0.09178685\n",
      "   0.14077074 -0.00195657  0.01969248 -0.07483935 -0.02334276 -0.04803085\n",
      "  -0.15479922  0.19923491  0.08984261  0.01940739  0.00734937  0.10242692\n",
      "  -0.11886105 -0.06966926 -0.15951116 -0.09856886  0.00829494  0.06992439\n",
      "  -0.03848459  0.02060041 -0.08283408  0.10119583 -0.00420807  0.06527385\n",
      "   0.01865646  0.11841718 -0.08801151 -0.02808351  0.06878789  0.03121737\n",
      "  -0.05141053 -0.05747203 -0.13225264 -0.00266419  0.05250697  0.05816787\n",
      "  -0.0729767   0.11199083 -0.0833469  -0.11075786 -0.03367874  0.07046639\n",
      "   0.13186012  0.00034744 -0.11526226  0.17384824 -0.12111973 -0.04390943\n",
      "  -0.08121166  0.1008698   0.15800218 -0.18551502  0.06203951  0.00058219\n",
      "   0.04980955  0.05997974 -0.14074314 -0.08363321  0.07339496  0.05507115\n",
      "   0.00338649  0.03261579  0.01619399  0.1162615   0.01812093 -0.05310897\n",
      "   0.12312317  0.03170208  0.01685026  0.01084322 -0.02977935 -0.01279867\n",
      "  -0.01856498  0.00996917  0.07850187  0.05918834  0.01531119  0.10587402\n",
      "   0.1445824  -0.18839774  0.02319676  0.08300025 -0.09912925 -0.07303088\n",
      "  -0.00563241 -0.04212719  0.00930487  0.03360642  0.06132268  0.01802212\n",
      "  -0.10166759  0.05253147 -0.17592837  0.12509275 -0.096662    0.0065751\n",
      "  -0.05946219  0.01504764  0.075338    0.08885703 -0.05637053  0.04453737\n",
      "  -0.02204886  0.10094086 -0.11758359  0.00538421 -0.11626405  0.1136473\n",
      "  -0.05103545 -0.02862435  0.02245459  0.08732496 -0.03125051  0.1070357\n",
      "  -0.06275059 -0.12186152]\n",
      " [ 0.04941718  0.03161199 -0.07830044 -0.0645629   0.15154712  0.17761038\n",
      "   0.09522917 -0.06034659 -0.00174674 -0.03974216  0.05956593  0.09920873\n",
      "   0.11267135  0.01528832 -0.05173153 -0.04668947 -0.03978171  0.02323882\n",
      "  -0.11939655  0.15288018  0.11390172 -0.00811282 -0.02310356  0.10890063\n",
      "  -0.07195534 -0.02066751 -0.10998334 -0.08090976  0.11134888  0.10779201\n",
      "   0.0008819   0.02585825 -0.08346384  0.03020773  0.02932199  0.10075274\n",
      "  -0.03040097  0.07959658 -0.03985219 -0.03949932  0.06181134  0.03902173\n",
      "  -0.06802818  0.02101741 -0.13533602 -0.018768    0.07991252  0.09038251\n",
      "  -0.08344434 -0.00658265 -0.13257181 -0.02614104 -0.05779525 -0.00676391\n",
      "   0.11109757  0.05058692 -0.14030849  0.23234418 -0.16584408 -0.02910898\n",
      "  -0.10932111  0.0577788   0.28288162 -0.14841934  0.08730862  0.01472483\n",
      "   0.02208349  0.06093518 -0.10694127  0.01152961  0.08211417  0.08279925\n",
      "  -0.00804629  0.01297596  0.00851633  0.07607121 -0.01064447  0.02493981\n",
      "   0.05942473 -0.06190957  0.00256406  0.10144599 -0.02910987 -0.01392372\n",
      "  -0.05750169  0.01188093  0.08037397  0.07658545  0.02235156  0.06928108\n",
      "   0.16947798 -0.15531333 -0.00627966  0.06968284 -0.00281545 -0.12211293\n",
      "  -0.04087033 -0.01819511  0.03496063  0.02041443  0.0567851  -0.00155039\n",
      "  -0.09015561  0.005497   -0.16107459  0.18203633 -0.04205063 -0.01416103\n",
      "  -0.00139695  0.00781295  0.05795903  0.07501964 -0.05427     0.06054149\n",
      "   0.03323882  0.08186694 -0.12704234 -0.02157155 -0.04460454  0.10792239\n",
      "  -0.0275025  -0.05710617 -0.00117776  0.07426108 -0.10884556  0.17093058\n",
      "  -0.07600921 -0.07497396]\n",
      " [ 0.0655468  -0.00435104  0.02507617 -0.05061866  0.14765024  0.16371498\n",
      "   0.08712002 -0.01079693 -0.08991523 -0.05356126 -0.00970495  0.08017322\n",
      "   0.1037062   0.04439491  0.09740682 -0.0668091  -0.01255572 -0.05621595\n",
      "  -0.06455118  0.1654042   0.04649843  0.01411356  0.02726613  0.10721645\n",
      "  -0.05449168 -0.05398873 -0.1489741  -0.07337435  0.05291614  0.04374\n",
      "  -0.00699073  0.01748291 -0.06145976  0.07171273  0.00558467  0.09610301\n",
      "   0.02024678  0.08349278 -0.03563979 -0.02413891  0.08410305  0.02918743\n",
      "  -0.05474888 -0.12076844 -0.13947579  0.04088621  0.06531423  0.05004709\n",
      "  -0.08467601  0.04900769 -0.11704268 -0.08012011  0.01360338  0.03048422\n",
      "   0.10324371  0.02541886 -0.08867914  0.19073412 -0.15049048  0.00363198\n",
      "  -0.09618294  0.14265342  0.13863597 -0.18857309  0.08513884  0.11547893\n",
      "   0.03809695  0.06126677 -0.14858733 -0.06748342  0.05653759  0.0873887\n",
      "  -0.03096045  0.04022737  0.08031133  0.11979199  0.01238383 -0.06592946\n",
      "   0.14338931  0.01142463 -0.00314848  0.03186926 -0.02249195 -0.01125628\n",
      "  -0.00681117 -0.00271845  0.05423465  0.0703045  -0.01906627  0.09630333\n",
      "   0.17204442 -0.11115833  0.05932247  0.12758431 -0.08078453 -0.09014717\n",
      "  -0.01325637 -0.01917377  0.03404281  0.01691277  0.03863573 -0.02683243\n",
      "  -0.09959889  0.00111415 -0.16713612  0.17990779 -0.04728463 -0.03045055\n",
      "  -0.01761002  0.0049436   0.07446678  0.08705697 -0.00788572  0.01945058\n",
      "   0.00300345  0.08379246 -0.14237069  0.02276044 -0.09877185  0.13021804\n",
      "  -0.0244868  -0.06953212 -0.01509511  0.06153513 -0.06991062  0.17417132\n",
      "  -0.05287695 -0.1050228 ]\n",
      " [ 0.11303739 -0.00637725  0.02204195 -0.00304529  0.13441357  0.17486111\n",
      "   0.13401882 -0.02388551 -0.03197195 -0.08340247 -0.01756945  0.08274451\n",
      "   0.12731583  0.01236195  0.06125314 -0.08014788  0.02052417 -0.01759442\n",
      "  -0.12343648  0.16265894  0.08087764  0.01126321 -0.0093028   0.15868767\n",
      "  -0.07888231 -0.11528487 -0.19897113 -0.10613376 -0.00561442  0.10142001\n",
      "  -0.00516455  0.06666489 -0.07719053  0.1134144   0.02059686  0.06754375\n",
      "   0.05199377  0.07345356 -0.06652731 -0.0469186   0.07609863  0.0147054\n",
      "  -0.0311982  -0.12527484 -0.10374073  0.01713654  0.04250732  0.05009875\n",
      "  -0.06170136  0.07361262 -0.05092248 -0.11268702  0.03171326  0.04181311\n",
      "   0.12442336  0.02841579 -0.09388638  0.15518783 -0.10117963 -0.01243814\n",
      "  -0.06297892  0.13699745  0.08406595 -0.23678374  0.07422529  0.03265497\n",
      "   0.05674607  0.022434   -0.18906227 -0.07038199  0.05429387  0.04770079\n",
      "  -0.03853353  0.01236935  0.01180453  0.13202315  0.05009272 -0.05103462\n",
      "   0.12961108  0.03250551 -0.00589856  0.02766928 -0.04023447 -0.01553659\n",
      "   0.01280731  0.00584477  0.05431786  0.01322668 -0.04535691  0.12352341\n",
      "   0.13858398 -0.15892583  0.0752203   0.09646268 -0.11649717 -0.0398095\n",
      "  -0.01286277 -0.04856157  0.03733646  0.04342028  0.09393595  0.02123811\n",
      "  -0.10910448  0.06432363 -0.13854719  0.10372482 -0.06976737 -0.03179063\n",
      "  -0.07145281  0.04880487  0.0392229   0.05497644 -0.03499154 -0.0004306\n",
      "  -0.02837215  0.10283943 -0.12609013  0.01292844 -0.14091599  0.13340548\n",
      "  -0.02966476 -0.02521426 -0.01945157  0.08035721 -0.03087206  0.13622452\n",
      "  -0.06401391 -0.14384979]]\n",
      "face 97 : [9, 10, 12, 13, 26, 34, 39, 42, 43, 53, 59, 63, 64, 65, 68, 72, 73, 75, 85, 91, 94, 97, 102, 103, 107, 111, 113, 132, 136, 142, 170, 178, 183, 191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face 107 : [4, 6, 15, 19, 22, 38, 47, 50, 58, 69, 87, 95, 96, 109, 130, 131, 133, 138, 143, 144, 158, 160, 175, 179, 188]\n",
      "face 109 : [32, 33, 45, 54, 57, 62, 77, 80, 84, 89, 98, 100, 105, 106, 108, 117, 119, 122, 135, 140, 145, 157, 161, 165, 180, 186, 187, 189, 192, 194, 197]\n",
      "face 116 : [8, 17, 18, 20, 27, 28, 37, 40, 44, 55, 60, 67, 74, 76, 82, 86, 90, 92, 93, 99, 110, 118, 121, 126, 127, 128, 129, 134, 137, 141, 147, 151, 153, 155, 159, 163, 167, 173, 181, 185, 196]\n",
      "face 119 : [9, 10, 12, 13, 26, 34, 39, 42, 43, 53, 59, 63, 64, 65, 68, 72, 73, 75, 85, 91, 94, 97, 102, 103, 107, 111, 113, 132, 136, 142, 170, 178, 183, 191]\n",
      "face 126 : [3, 21, 24, 25, 29, 30, 35, 41, 46, 49, 51, 71, 78, 104, 114, 115, 120, 123, 124, 125, 139, 146, 150, 152, 164, 166, 168, 169, 171, 174, 176, 182, 193, 195]\n",
      "face 600 : no matching\n"
     ]
    }
   ],
   "source": [
    "load_dataset()\n",
    "model = load_facenet()\n",
    "X = []\n",
    "for i in range(200):\n",
    "    img1 = cv2.imread(\"a5/saved_faces/face_image_\"+str(i)+\".jpg\")\n",
    "    embedding = img_to_encoding(img1,model).tolist()\n",
    "    X.append(embedding)\n",
    "    np.save(\"a5/saved_faces/face_image_\"+str(i),embedding)\n",
    "X = np.array(X).reshape(200,128)\n",
    "print(X.shape)\n",
    "inverted_dict, visual_word = compute_Kmeans(X)\n",
    "np.save(\"a5/saved_faces/visual_word\",visual_word)\n",
    "img0 = cv2.imread(\"a5/input_faces/face_image_97.jpg\")\n",
    "img0 = cv2.resize(img0, (96, 96))\n",
    "matching0 = matching(img0,model,visual_word)\n",
    "print(\"face 97 : \"+str(inverted_dict[matching0]))\n",
    "\n",
    "img1 = cv2.imread(\"a5/input_faces/face_image_107.jpg\")\n",
    "img1 = cv2.resize(img1, (96, 96))\n",
    "matching1 = matching(img1,model,visual_word)\n",
    "print(\"face 107 : \"+str(inverted_dict[matching1]))\n",
    "\n",
    "img2 = cv2.imread(\"a5/input_faces/face_image_109.jpg\")\n",
    "img2 = cv2.resize(img2, (96, 96))\n",
    "matching2 = matching(img2,model,visual_word)\n",
    "print(\"face 109 : \"+str(inverted_dict[matching2]))\n",
    "\n",
    "img3 = cv2.imread(\"a5/input_faces/face_image_116.jpg\")\n",
    "img3 = cv2.resize(img3, (96, 96))\n",
    "matching3 = matching(img3,model,visual_word)\n",
    "print(\"face 116 : \"+str(inverted_dict[matching3]))\n",
    "\n",
    "img4 = cv2.imread(\"a5/input_faces/face_image_119.jpg\")\n",
    "img4 = cv2.resize(img4, (96, 96))\n",
    "matching4 = matching(img4,model,visual_word)\n",
    "print(\"face 119 : \"+str(inverted_dict[matching4]))\n",
    "\n",
    "img5 = cv2.imread(\"a5/input_faces/face_image_126.jpg\")\n",
    "img5 = cv2.resize(img5, (96, 96))\n",
    "matching5 = matching(img5,model,visual_word)\n",
    "print(\"face 126 : \"+str(inverted_dict[matching5]))\n",
    "\n",
    "img6 = cv2.imread(\"a5/input_faces/face_image_600.jpg\")\n",
    "img6 = cv2.resize(img6, (96, 96))\n",
    "matching6 = matching(img6,model,visual_word)\n",
    "print(\"face 600 : \"+str(inverted_dict[matching6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\Anaconda3\\envs\\python3\\lib\\site-packages\\keras\\engine\\saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'predict_on_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5ec5f57d20e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a5/input_faces/face_image_97.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmatching0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvisual_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"face 97 : \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-4a7f6089f2bc>\u001b[0m in \u001b[0;36mmatching\u001b[1;34m(img, model, visual_word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvisual_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mref_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmax_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmax_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisual_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-84efff68fee1>\u001b[0m in \u001b[0;36mimg_to_encoding\u001b[1;34m(img1, model)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'predict_on_batch'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
